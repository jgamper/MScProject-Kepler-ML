{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import display\n",
    "import progressbar\n",
    "\n",
    "# pd.options.display.max_columns = None\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# raw_path = '/home/jevgenji/Dropbox/Projects/MScProject-Kepler-ML/data/raw'\n",
    "# processed_path = '/home/jevgenji/Dropbox/Projects/MScProject-Kepler-ML/data/processed'\n",
    "\n",
    "# tce_table = pd.read_csv(os.path.join(raw_path, 'tcetable.csv'))\n",
    "# koi_table = pd.read_csv(os.path.join(raw_path, 'cumulative.csv'))\n",
    "# som_table = pd.read_table(os.path.join(raw_path,'Table2_Kepler.txt'), delimiter=',')\n",
    "# fpp_table = pd.read_csv(os.path.join(raw_path, 'koifpp.csv'))\n",
    "# som_table.columns = ['kepid', 'Theta1', 'Theta2 ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a common koi_planet name code for all tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tce_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kepid_plnt = []\n",
    "for i, tce_plnt_num in enumerate(tce_table.tce_plnt_num.values):\n",
    "    num = str(tce_plnt_num)\n",
    "    if len(num) < 2:\n",
    "        num = '0' + num\n",
    "    kepid_plnt.append(str(tce_table.kepid.values[i]) + '.' + num)\n",
    "tce_table['kepid_plnt'] = kepid_plnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(tce_table[['kepid_plnt', 'kepid', 'tce_plnt_num']].head())\n",
    "tce_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# koi_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixel_based_names = ['koi_fwm_stat_sig', 'koi_fwm_sra', 'koi_fwm_sra_err', 'koi_fwm_sdec', 'koi_fwm_sdec_err', 'koi_fwm_srao', 'koi_fwm_srao_err', 'koi_fwm_sdeco', 'koi_fwm_sdeco_err', 'koi_fwm_prao', 'koi_fwm_prao_err', 'koi_fwm_pdeco', 'koi_fwm_pdeco_err', 'koi_dicco_mra', 'koi_dicco_mra_err', 'koi_dicco_mdec', 'koi_dicco_mdec_err', 'koi_dicco_msky', 'koi_dicco_msky_err', \\\n",
    "                     'koi_dicco_fra', 'koi_dicco_fra_err', 'koi_dicco_fdec', 'koi_dicco_fdec_err', 'koi_dicco_fsky', 'koi_dicco_fsky_err', 'koi_dikco_mra', 'koi_dikco_mra_err', 'koi_dikco_mdec', 'koi_dikco_mdec_err', 'koi_dikco_msky', 'koi_dikco_msky_err', 'koi_dikco_fra', 'koi_dikco_fra_err', 'koi_dikco_fdec', 'koi_dikco_fdec_err', 'koi_dikco_fsky', 'koi_dikco_fsky_err']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kepid_plnt = []\n",
    "for i, kepoi_name in enumerate(koi_table['kepoi_name'].values):\n",
    "    kepid_plnt.append(str(koi_table.kepid.values[i]) + '.' + kepoi_name[-2:])\n",
    "    \n",
    "koi_table['kepid_plnt'] = kepid_plnt\n",
    "display_list = ['kepid_plnt', 'kepid', 'kepoi_name', 'koi_disposition'] + pixel_based_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(koi_table[display_list].head())\n",
    "koi_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fpp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(fpp_table.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kepid_plnt = []\n",
    "for i, kepoi_name in enumerate(fpp_table['kepoi_name'].values):\n",
    "    kepid_plnt.append(str(fpp_table.kepid.values[i]) + '.' + kepoi_name[-2:])\n",
    "    \n",
    "fpp_table['kepid_plnt'] = kepid_plnt\n",
    "fpp_table = fpp_table[['kepid_plnt', 'fpp_prob', 'fpp_score', 'fpp_spec_occrate']]\n",
    "display(fpp_table.head(3))\n",
    "fpp_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values in fpp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(fpp_table.isnull().values.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpp_table = fpp_table.dropna(axis=0)\n",
    "fpp_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Link koi_table and tce_table into target_data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_data = pd.merge(koi_table[['kepid_plnt', 'koi_disposition']+pixel_based_names], tce_table, on='kepid_plnt')\n",
    "del target_data['rowid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key, value in target_data.dtypes.to_dict().items():\n",
    "    if key not in ['kepid_pnlt', 'koi_disposition', 'koi_pdisposition', 'kepid_plnt'] and value == np.dtype('O'):\n",
    "        target_data.drop(key, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autovetter_stuff = ['av_vf_pc', 'av_vf_afp', 'av_vf_ntp', 'av_vf_afp_err', 'av_vf_ntp_err',\n",
    "                    'av_pp_pc', 'av_pp_afp', 'av_pp_ntp', 'av_training_set', 'av_pred_class', 'av_vf_pc_err']\n",
    "\n",
    "# Pixel based statistics are missing, try redownloading with errors\n",
    "zeros = ['tce_eccen', 'tce_longp', 'tce_nkoi'] \n",
    "\n",
    "nans = ['tce_ioflag', 'tcet_period',\n",
    " 'tcet_time0bk',\n",
    " 'tcet_time0',\n",
    " 'tcet_duration',\n",
    " 'tcet_ingress',\n",
    " 'tcet_depth']\n",
    "\n",
    "other_questionable_things = ['tce_quarters', 'tce_rb_tcount1', 'tce_dicco_fra_err', 'tce_dicco_fdec_err',\n",
    "                             'tcet_time0_err', 'tce_plnt_num', 'tce_eccen_err', 'tce_dikco_fra', 'tce_dikco_fdec',\n",
    "                             'tce_dikco_fsky', 'tce_dicco_fra', 'tce_dicco_fdec', 'tce_dicco_fsky',\n",
    "                            'tce_rb_tcount2', 'tce_rb_tcount3', 'tce_rb_tcount4', 'tcet_period_err', 'tce_longp_err',\n",
    "                            'tcet_time0bk_err', 'tcet_duration_err', 'tcet_ingress_err', 'tcet_depth_err',\n",
    "                            'tce_dicco_fsky_err', 'tce_dikco_fra_err', 'tce_dikco_fdec_err', 'tce_dikco_fsky_err']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_drops = autovetter_stuff + zeros + nans + other_questionable_things\n",
    "target_data.drop(all_drops, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take care of som_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(som_table.head(3))\n",
    "som_table.shape\n",
    "print('Unique: {}'.format(len(np.unique(som_table.kepid.values.astype(np.int)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "som_table.drop_duplicates(inplace=True, subset='kepid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "som_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add som features, see how big the data would be then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_data_test = pd.merge(target_data, som_table, on='kepid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target_data.drop_duplicates(subset='kepid_pnlt', inplace=True)\n",
    "target_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.sum(target_data_test.duplicated('kepid_plnt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how big is the intersection betwee target_data_test,which is with som and fpp_table based on kepid_plnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersection = pd.merge(target_data_test, fpp_table, how='inner', on='kepid_plnt')\n",
    "intersection.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many fp and confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersection.koi_disposition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2238+1810"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From this intersection lets get fpp_table and target_data table based on target_data_test column names, and fpp_table column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_data = intersection[list(target_data.columns) + ['Theta1']]\n",
    "display(target_data.head(3))\n",
    "target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpp_table = intersection[fpp_table.columns]\n",
    "display(fpp_table.head(3))\n",
    "fpp_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save fpp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpp_table.to_csv(os.path.join(processed_path,'fppTableReady.csv'), index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max ephemeris function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "koi_list = target_data.kepid.values.tolist()\n",
    "max_corr = []\n",
    "bar = progressbar.ProgressBar(max_value=target_data.shape[0])\n",
    "for index, row in target_data.iterrows():\n",
    "    local_corrs = []\n",
    "    current_kepid = row['kepid']\n",
    "    \n",
    "    orbital_period1 = int(row['tce_period']*1440)\n",
    "    transit_duration1 = int((row['tce_duration']*60)/2) # get on both sides, since its on center\n",
    "    transit_epoch1 = int(row['tce_time0bk']*1440) # get in minutes\n",
    "    \n",
    "    array1 = np.zeros(2141280)\n",
    "\n",
    "    # populate the array\n",
    "    for i in range(transit_epoch1, 2141280, orbital_period1):\n",
    "        array1[i-transit_duration1:i+transit_duration1] = 1\n",
    "        \n",
    "    # check if orbital period is less than the first transit\n",
    "    if transit_epoch1/orbital_period1 > 1:\n",
    "        for i in range(transit_epoch1, 0, -orbital_period1):\n",
    "            array1[i-transit_duration1:i+transit_duration1] = 1\n",
    "\n",
    "    # search for other TCE on the same star\n",
    "    indexes = [i for i, val in enumerate(koi_list) if val == current_kepid]\n",
    "    \n",
    "    # test if the only TCE on that star\n",
    "    if len(indexes) == 1:\n",
    "        # if so then the value is zero\n",
    "        max_corr.append(0)\n",
    "    else:\n",
    "        for i in indexes:            \n",
    "            orbital_period2 = int(target_data.iloc[[i]]['tce_period']*1440)\n",
    "            transit_duration2 = int((target_data.iloc[[i]]['tce_duration']*60)/2)\n",
    "            transit_epoch2 = int(target_data.iloc[[i]]['tce_time0bk']*1440) # questionable, which one to use\n",
    "\n",
    "            array2 = np.zeros(2141280)\n",
    "            \n",
    "            for i in range(transit_epoch2, 2141280, orbital_period2):\n",
    "                array2[i-transit_duration2:i+transit_duration2] = 1\n",
    "                \n",
    "            if transit_epoch1/orbital_period1 > 1:\n",
    "                for i in range(transit_epoch1, 0, -orbital_period1):\n",
    "                    array1[i-transit_duration1:i+transit_duration1] = 1\n",
    "\n",
    "            p = np.dot((array1)/np.sqrt(np.sum(array1)), (array2)/np.sqrt(np.sum(array2)))\n",
    "\n",
    "            local_corrs.append(p)\n",
    "        \n",
    "        local_corrs = np.array(local_corrs)\n",
    "        max_corr.append(np.max(local_corrs))\n",
    "    bar.update(index)\n",
    "#     if index == 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_data['max_ephemeris_corr'] = max_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(17,10));\n",
    "target_data.hist(column=\"max_ephemeris_corr\", bins=100);\n",
    "plt.xlabel(\"corr\",fontsize=15);\n",
    "plt.ylabel(\"Frequency\",fontsize=15);\n",
    "plt.xlim([0.0,1.0]);\n",
    "# plt.savefig('max_ephemerics_corr_hist.png', dpi=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_data.isnull().values.sum(axis=0)\n",
    "nan_cols = np.where(target_data.isnull().values.sum(axis=0) == 1)[0]\n",
    "[target_data.columns[i] for i in nan_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_data.koi_disposition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(target_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_save = target_data[['kepid_plnt','koi_disposition','max_ephemeris_corr', \n",
    "                     'wst_robstat', 'tce_cap_stat', 'tce_hap_stat', 'koi_fwm_stat_sig', 'tce_rminmes',\n",
    "                     'tce_max_mult_ev', 'tce_albedo_stat', 'tce_period', 'tce_prad', 'tce_model_snr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_save.to_csv('for_SNR.csv',  sep=',', index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_last = target_data[['kepid_plnt','koi_disposition','max_ephemeris_corr', \n",
    "                     'wst_robstat', 'tce_cap_stat', 'tce_hap_stat', 'koi_fwm_stat_sig', 'tce_rminmes',\n",
    "                     'tce_max_mult_ev', 'tce_albedo_stat', 'Theta1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_data = target_last\n",
    "target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler as scaler\n",
    "scaled_df = pd.DataFrame()\n",
    "no_scaling = ['kepid_plnt', 'koi_disposition', 'koi_pdisposition', 'kepid']\n",
    "i = 0\n",
    "for col_name, series in target_data.iteritems():\n",
    "    \n",
    "    not_nans = ~pd.isnull(series.values)\n",
    "        \n",
    "    if col_name in no_scaling:\n",
    "        scaled_df[col_name] = target_data[col_name]\n",
    "        \n",
    "    elif np.sum(pd.isnull(series.values)) > 5000:\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        if np.max(series.values[not_nans]) > 1:\n",
    "            nans = np.sum(np.isnan(series.values))\n",
    "            if nans > 0:\n",
    "                s = series\n",
    "                scaled_df[col_name] = s.sub(s.min()).div((s.max() - s.min()))\n",
    "            else:\n",
    "                scaled_df[col_name] = scaler().fit_transform(X=series.values.reshape(-1, 1))\n",
    "        else:\n",
    "            scaled_df[col_name] = series.values\n",
    "            \n",
    "display(scaled_df.describe())\n",
    "scaled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_df.to_csv(os.path.join(processed_path,'scaledMonJul31.csv'), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp_conf_table = scaled_df.loc[scaled_df['koi_disposition'].isin(['CONFIRMED', 'FALSE POSITIVE'])]\n",
    "# fp_conf_table.drop(['kepid'], axis = 1, inplace=True)\n",
    "fp_conf_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp_conf_table.koi_disposition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp_conf_table.isnull().values.sum(axis=0)\n",
    "nan_cols = np.where(fp_conf_table.isnull().values.sum(axis=0) == 1)[0]\n",
    "fp_conf_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# insert class conditional means and drop some of the data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp_conf_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col_index, col in enumerate(fp_conf_table):\n",
    "    if fp_conf_table[col].dtype != 'object':\n",
    "        fp_conf_table[col].fillna(fp_conf_table.groupby(['koi_disposition'])[col].transform('mean'), inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp_conf_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp_conf_table.koi_disposition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp_conf_table.isnull().values.sum(axis=0)\n",
    "nan_cols = np.where(fp_conf_table.isnull().values.sum(axis=0) == 1)[0]\n",
    "fp_conf_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp_conf_table.to_csv(os.path.join(processed_path, 'fp_conf_tableMonJul31.csv'), sep=',', index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled.to_csv(os.path.join(processed_path, 'unlabeled_tableMonJul31.csv'), sep=',', index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Discriminative GPLVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from GPflow.model import GPModel\n",
    "import GPflow as GP\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "Y = iris.data  # we only take the first two features.\n",
    "Y.shape\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y, target = Y[(target == 0)| (target == 1), :], target[(target == 0) | (target == 1)]\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import GPflow\n",
    "from GPflow import ekernels\n",
    "from GPflow import kernels\n",
    "from GPflow import densities\n",
    "from GPflow import settings\n",
    "from sklearn.covariance import empirical_covariance\n",
    "from numpy.linalg import inv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "np.random.seed(42)\n",
    "GPflow.settings.numerics.quadrature = 'error' \n",
    "\n",
    "float_type = settings.dtypes.float_type\n",
    "np_float_type = np.float32 if float_type is tf.float32 else np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "Y = iris.data\n",
    "my_target = iris.target\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1, t2 = 3, 9\n",
    "Y = Y[(my_target == t1) | (my_target == t2), :]\n",
    "my_target = my_target[(my_target == t1) | (my_target == t2)]\n",
    "print(Y.shape)\n",
    "print(my_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = x_train.astype(np.float64).reshape(60000, 784)\n",
    "my_target = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = Y[1:100]\n",
    "my_target = my_target[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.lib.function_base import average\n",
    "\n",
    "class DiscriminativePrior(GPflow.priors.Prior):\n",
    "    \n",
    "    def __init__(self, mu, var, my_target, n_latent):\n",
    "        \n",
    "        GPflow.priors.Prior.__init__(self)\n",
    "        self.mu = np.atleast_1d(np.array(mu, np_float_type))\n",
    "        self.var = np.atleast_1d(np.array(var, np_float_type))\n",
    "        print(self.var.shape)\n",
    "        # Get global target \n",
    "        self.target = my_target\n",
    "        # Get number of classes \n",
    "        self.classes = np.unique(self.target)\n",
    "        # Number of latent dimensions\n",
    "        self.n_latent = n_latent\n",
    "        \n",
    "    def logp(self, x):\n",
    "        return tf.reduce_sum(densities.gaussian(self._jInv(x), self.mu, self.var))\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"N(\"+str(self.mu) + \",\" + str(self.var) + \")\"\n",
    "    \n",
    "    def _jInv(self, x):\n",
    "        \"\"\"\n",
    "        Computes in-class and between class separability as in LDA\n",
    "        \"\"\"      \n",
    "        Sb = self._SbFunction(x)\n",
    "        \n",
    "        Sw = self._SwFunction(x)\n",
    "        \n",
    "        J_of_x = tf.trace( tf.matmul(tf.matrix_inverse(Sw), Sb) )\n",
    "        \n",
    "        return 1 / J_of_x\n",
    "    \n",
    "    @staticmethod\n",
    "    def _scatterTF(x):\n",
    "        \"\"\"\n",
    "        Computes covariance matrix for a given tensor\n",
    "        \"\"\"\n",
    "        N = x.get_shape()[1]\n",
    "        \n",
    "        # Substract mean\n",
    "        x -= tf.reduce_mean(x, 0, keep_dims=True)\n",
    "\n",
    "        # Make transpose\n",
    "        x_T = tf.transpose(x)\n",
    "\n",
    "        # Compute the scatter\n",
    "        return tf.matmul(x_T, x)\n",
    "        \n",
    "    def _SwFunction(self, x):\n",
    "        \"\"\"\n",
    "        Computes within-class scatter matrix Sw\n",
    "        \"\"\"\n",
    "        Sw = np.zeros((self.n_latent, self.n_latent))\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            \n",
    "            indx = np.where(self.target == cls)\n",
    "            \n",
    "            Xg = tf.gather_nd(x, [[i] for i in indx[0]])\n",
    "            \n",
    "            Sw = tf.add(Sw, self._scatterTF(Xg))\n",
    "\n",
    "        return Sw\n",
    "    \n",
    "    def _SbFunction(self, x):\n",
    "        \"\"\"\n",
    "        Computes between class scatter matrix Sb\n",
    "        \"\"\"\n",
    "        global_means = tf.reduce_mean(x, 0, keep_dims=True)\n",
    "        \n",
    "        Sb = np.zeros((self.n_latent, self.n_latent))\n",
    "\n",
    "        # Iterate over classes \n",
    "        for cls in self.classes:\n",
    "            \n",
    "            # Get indicies according to target value i.e. which class\n",
    "            indx = np.where(self.target == cls)\n",
    "  \n",
    "            # Select the necessary rows given the indx above into a new tensor for that class\n",
    "            Xg = tf.gather_nd(x, [[i] for i in indx[0]])\n",
    "            \n",
    "            # Get N_i for the class\n",
    "            N_i = Xg.get_shape()[1]\n",
    "            \n",
    "            # Compute class means \n",
    "            class_means = tf.reduce_mean(x, 0, keep_dims=True)\n",
    "            \n",
    "            diff = tf.subtract(class_means, global_means)\n",
    "            \n",
    "            diff_T = tf.transpose(diff)\n",
    "            \n",
    "            matmul = tf.matmul(diff_T, diff)\n",
    "            \n",
    "            Sb = tf.add(Sb, matmul)\n",
    "        \n",
    "        return Sb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = GPflow.gplvm.GPLVM(Y, latent_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.X.prior = DiscriminativePrior(0, 1, my_target=my_target, n_latent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = m.X.value\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(result[:,0], result[:,1], c=my_target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sort out wget file for light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_table = pd.read_csv(os.path.join(processed_path, 'fp_conf_tableMonJul31.csv'))\n",
    "unlabeled_table = pd.read_csv(os.path.join(processed_path, 'unlabeled_tableMonJul31.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_index = list(unlabeled_table.kepid_plnt.values.astype('str')) + list(total_table.kepid_plnt.values.astype('str'))\n",
    "len(total_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(total_index[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_index_kepid = [string[:-3] for string in total_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(raw_path, 'download_exoarch_6628.txt')) as f:\n",
    "          content = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(999,1110,2):\n",
    "#     print(content[i].split(\"kplr\")[1].split()[0][26:28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odd_to_save = []\n",
    "even_to_save = []\n",
    "kepids = []\n",
    "indexes = []\n",
    "for i in range(0, len(content), 2):\n",
    "\n",
    "    index = content[i].split(\"kplr\")[1].split()[0][:15].split('0',1)[1].split('-',1)[0]\n",
    "    # check if starts with zero, drop 0th string\n",
    "    if index[0] == '0':\n",
    "        index = index[1:]\n",
    "    kepid_plnt = index+'.'+content[i+1].split(\"kplr\")[1].split()[0][26:28]\n",
    "    kepids.append(kepid_plnt)\n",
    "    if kepid_plnt in total_index:\n",
    "#         print('\\n')\n",
    "#         print(i)\n",
    "#         print(index)\n",
    "        indexes.append(index)\n",
    "        odd_to_save.append(i)\n",
    "        even_to_save.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(total_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_content = [content[i] for i in even_to_save]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_content[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(filtered_content) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ll = []\n",
    "for i in range(0, len(filtered_content), 1047):\n",
    "    ll.append(filtered_content[i:i+1047])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ind, l in enumerate(ll):\n",
    "    with open(os.path.join(processed_path, 'filtered_wget_{}.txt'.format(ind)), 'w') as f:\n",
    "        f.writelines(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path = '/home/jevgenji/Desktop/filtered_wget_0/kplr001026957_q1_q17_dr25_tce_01_dvt_lc.tbl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astropy.table import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = Table.read(test_path, format='ipac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IBCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from edward.models import Dirichlet, Exponential, Categorical, Empirical\n",
    "import edward as ed\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import display\n",
    "np.set_printoptions(precision=2,suppress=True)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(I, J, K, nu_vec, lambda_mat):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        I - int, number of instances\n",
    "        J - int, number of classes\n",
    "        K - int, number of classifiers \n",
    "        nu_vec - hyper parameter array of shape (J,) for dirichlet prior over categorical for t_i\n",
    "        lambda_mat - a hyper param array of shape (J, J) for exponential prior over Dirichlet \n",
    "    Outputs:\n",
    "        A (I, K) array of K predictions for each instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if nu_vec has the corresponding (1,J) size\n",
    "    nu_vec = np.array(nu_vec)\n",
    "    assert nu_vec.shape == (J,), 'Wrong shape of parameter array nu!'\n",
    "    \n",
    "    # Check if lambda_mat is of shape (J, J)\n",
    "    lambda_mat = np.array(lambda_mat)\n",
    "    assert lambda_mat.shape == (J, J), 'Wrong shape of parameter lamda_mat'\n",
    "    \n",
    "    # Generate t vector\n",
    "    p_vec = Dirichlet( concentration = nu_vec )\n",
    "    t = Categorical( probs= p_vec, sample_shape = I)\n",
    "   \n",
    "    # Reshape lambda_mat to be of shape (K, J, J), a K copies of (J,J) matrix\n",
    "    lambda_mat = tf.reshape( tf.concat([lambda_mat for _ in range(K)], axis=0), [K, J, J] )\n",
    "    \n",
    "    # Continue into generating c vector\n",
    "    alpha = Exponential( rate = lambda_mat )\n",
    "    pi = Dirichlet( concentration = alpha ) # Confusion matrices of shape (K, J, J)\n",
    "    c = [Categorical( probs = tf.gather(pi[k], t) ) for k in range(K)] # iterate over k_i\n",
    "    \n",
    "    return sess.run([c, pi, t, p_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "I = 100\n",
    "J = 3\n",
    "K = 4\n",
    "nu_vec = np.array([1. for _ in range(J)], dtype=np.float32)\n",
    "lambda_mat = np.array([[.3, 3., 2.], [2., .5, 3.], [2., 3., .5]], dtype=np.float32)\n",
    "lambda_mat.dtype = 'float32'\n",
    "c_train, true_conf, true_t, true_p = build_dataset(I, J, K, np.ones(J), np.ones([J, J]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_0</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>true_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    c_0  c_1  c_2  c_3  true_t\n",
       "0     0    2    0    0       2\n",
       "1     2    2    2    0       2\n",
       "2     0    2    0    0       2\n",
       "3     0    2    2    1       2\n",
       "4     2    2    0    1       0\n",
       "5     2    0    0    0       2\n",
       "6     0    2    0    0       2\n",
       "7     1    1    2    0       2\n",
       "8     1    2    0    2       1\n",
       "9     0    2    2    0       2\n",
       "10    2    2    2    0       2\n",
       "11    2    2    0    0       2\n",
       "12    2    2    0    1       2\n",
       "13    2    2    2    1       2\n",
       "14    0    2    0    0       2\n",
       "15    0    2    0    2       2\n",
       "16    1    2    2    2       1\n",
       "17    0    2    2    0       2\n",
       "18    2    2    0    2       2\n",
       "19    0    1    2    0       2\n",
       "20    0    1    0    0       2\n",
       "21    1    0    0    0       1\n",
       "22    1    0    0    0       1\n",
       "23    2    2    0    0       2\n",
       "24    2    0    0    2       2\n",
       "25    1    2    0    0       1\n",
       "26    0    2    0    2       2\n",
       "27    2    0    2    0       2\n",
       "28    2    2    0    2       2\n",
       "29    2    1    0    1       0\n",
       "..  ...  ...  ...  ...     ...\n",
       "70    0    2    2    0       2\n",
       "71    2    2    2    1       2\n",
       "72    1    2    0    0       1\n",
       "73    1    2    0    0       1\n",
       "74    2    1    1    1       0\n",
       "75    0    2    2    0       2\n",
       "76    0    0    0    0       2\n",
       "77    2    2    0    0       2\n",
       "78    1    2    0    0       1\n",
       "79    2    2    0    1       0\n",
       "80    2    2    0    1       0\n",
       "81    0    0    0    0       2\n",
       "82    1    2    0    0       1\n",
       "83    1    2    2    2       1\n",
       "84    2    2    2    2       0\n",
       "85    0    1    0    2       2\n",
       "86    2    2    0    0       2\n",
       "87    2    2    0    1       0\n",
       "88    2    2    2    0       2\n",
       "89    2    2    0    1       2\n",
       "90    2    2    2    0       2\n",
       "91    2    2    0    2       2\n",
       "92    0    2    0    1       2\n",
       "93    0    2    2    0       2\n",
       "94    2    1    0    1       0\n",
       "95    1    2    0    2       1\n",
       "96    2    1    1    1       0\n",
       "97    0    0    2    0       2\n",
       "98    2    0    0    2       2\n",
       "99    2    1    2    0       2\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data = pd.DataFrame({**{'c_{}'.format(i): c_train[i] for i in range(len(c_train))}, **{'true_t': true_t} } )\n",
    "display(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23,  0.16,  0.62])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forward model\n",
    "I = 100\n",
    "J = 3\n",
    "K = 4\n",
    "# Generate t vector\n",
    "p_vec = Dirichlet( concentration = tf.ones(J))\n",
    "t = Categorical( logits = p_vec, sample_shape = I )\n",
    "\n",
    "# Continue into generating c vector\n",
    "alpha = [Exponential( rate = tf.ones([J,J]) ) for _ in range(K)]\n",
    "pi = [Dirichlet( concentration = alpha[k] ) for k in range(K)]\n",
    "c_forward = [Categorical( logits = tf.gather(pi[k], t) ) for k in range(K)] # iterate over k_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T = 1000 # Number of MCMC samples\n",
    "\n",
    "q_p_vec = Empirical(tf.Variable(tf.ones([T, J])))\n",
    "q_t = Empirical(tf.cast(tf.Variable(tf.ones([T, I])), tf.int32))\n",
    "\n",
    "q_alpha = [Empirical(tf.Variable(tf.ones([T, J, J]))) for _ in range(K)]\n",
    "q_pi = [Empirical(tf.Variable(tf.ones([T, J, J]))) for _ in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_vars=dict(list(zip(pi, q_pi))+list(zip(alpha, q_alpha))+[(t, q_t), (p_vec, q_p_vec)])\n",
    "\n",
    "inference = ed.HMC(latent_vars=latent_vars\n",
    "                   , data=dict(zip(c_forward, c_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dustins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import edward as ed\n",
    "import tensorflow as tf\n",
    "from edward.models import *\n",
    "\n",
    "def build_dataset(I, J, K, nu_vec, lambda_mat):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "      I - int, number of instances\n",
    "      J - int, number of classes\n",
    "      K - int, number of classifiers\n",
    "      nu_vec - hyper parameter array of shape (J,) for dirichlet prior over categorical for t_i\n",
    "      lambda_mat - a hyper param array of shape (J, J) for exponential prior over Dirichlet\n",
    "  Outputs:\n",
    "      A list c of length(K), where each element is an array of shape (I, )\n",
    "  \"\"\"\n",
    "\n",
    "  # Check if nu_vec has the corresponding (1,J) size\n",
    "  nu_vec = np.array(nu_vec)\n",
    "  assert nu_vec.shape == (J,), 'Wrong shape of parameter array nu!'\n",
    "\n",
    "  # Check if lambda_mat is of shape (J, J)\n",
    "  lambda_mat = np.array(lambda_mat)\n",
    "  assert lambda_mat.shape == (J, J), 'Wrong shape of parameter lamda_mat'\n",
    "\n",
    "  # Generate t vector\n",
    "  p_vec = Dirichlet( concentration = nu_vec )\n",
    "  t = Categorical( logits= p_vec, sample_shape = I)\n",
    "\n",
    "  # Reshape lambda_mat to be of shape (K, J, J), a K copies of (J,J) matrix\n",
    "  lambda_mat = tf.reshape( tf.concat([lambda_mat for _ in range(K)], axis=0), [K, J, J] )\n",
    "\n",
    "  # Continue into generating c vector\n",
    "  alpha = Exponential( rate = lambda_mat )\n",
    "  pi = Dirichlet( concentration = alpha ) # Confusion matrices of shape (K, J, J)\n",
    "  c = [Categorical( logits = tf.gather(pi[k], t) ) for k in range(K)] # iterate over k_i\n",
    "\n",
    "  sess = ed.get_session()\n",
    "  return sess.run([c, pi, t])\n",
    "\n",
    "# Forward model\n",
    "I = 100\n",
    "J = 3\n",
    "K = 4\n",
    "\n",
    "c, pi, t = build_dataset(I, J, K, np.ones(J), np.ones([J, J]))\n",
    "\n",
    "c_train = c\n",
    "\n",
    "# Generate t vector\n",
    "p_vec = Dirichlet( concentration = tf.ones([J])+10)\n",
    "t = Categorical( logits= p_vec, sample_shape = I )\n",
    "\n",
    "# Continue into generating c vector\n",
    "alpha = [Exponential( rate = tf.ones([J, J]) ) for _ in range(K)]\n",
    "pi = [Dirichlet( concentration = alpha[k] ) for k in range(K)]\n",
    "c_forward = [Categorical( logits = tf.gather(pi[k], t) ) for k in range(K)] # iterate over k_i\n",
    "\n",
    "# Trying the HMC code snippet\n",
    "T = 1000 # Number of MCMC samples\n",
    "\n",
    "q_p_vec = Empirical(tf.Variable(tf.ones([T, J])))\n",
    "q_t = Empirical(tf.cast(tf.Variable(tf.ones([T, I])), tf.int32))\n",
    "\n",
    "q_alpha = [Empirical(tf.Variable(tf.ones([T, J, J]))) for _ in range(K)]\n",
    "q_pi = [Empirical(tf.Variable(tf.ones([T, J, J]))) for _ in range(K)]\n",
    "latent_vars=dict(list(zip(pi, q_pi))+list(zip(alpha, q_alpha))+[(t, q_t), (p_vec, q_p_vec)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inference = ed.Gibbs(latent_vars,  data=dict(zip(c_forward, c_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import theano as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "I = 100\n",
    "J = 3\n",
    "K = 4\n",
    "nu_vec = np.array([1. for _ in range(J)], dtype=np.float32)\n",
    "lambda_mat = np.array([[.3, 3., 2.], [2., .5, 3.], [2., 3., .5]], dtype=np.float32)\n",
    "lambda_mat2 = np.array([[.5, 2.], [2., .5,]], dtype=np.float32)\n",
    "import theano as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "IBCC = pm.Model()\n",
    "\n",
    "with IBCC:\n",
    "    \n",
    "    p_vec = pm.Dirichlet(name='p_vec', a=nu_vec)\n",
    "\n",
    "    t = pm.Categorical(name='t', p=p_vec, shape=I)\n",
    "    \n",
    "    alpha = [pm.Exponential('alpha_{}'.format(k), lam=lambda_mat, shape=(J, J)) for k in range(K)]\n",
    "    \n",
    "    alpha = T.tensor.stack(alpha)\n",
    "    \n",
    "    pi = [[pm.Dirichlet('pi_j{}k{}'.format(j, k), a=alpha[k][j], shape=3) for j in range(J)] for k in range(K)]\n",
    "    \n",
    "    pi = T.tensor.stack(pi)\n",
    "    \n",
    "    c = [[] for k in range(K)]\n",
    "    \n",
    "    t_sample = t.random()\n",
    "    \n",
    "    for i in range(I):\n",
    "        \n",
    "        for k in range(K):\n",
    "\n",
    "            c[k].append(pm.Categorical('c_k{}i{}'.format(k, i), p=pi[k][t_sample[i]], observed=c_train[k][i]))\n",
    "        \n",
    "    c = T.tensor.stack(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50000/50000 [52:01<00:00, 16.02it/s] \n"
     ]
    }
   ],
   "source": [
    "with IBCC:\n",
    "    step1 = pm.sampling.CategoricalGibbsMetropolis([t, c])\n",
    "    step2 = pm.sampling.Metropolis([alpha, pi, p_vec])\n",
    "    trace = pm.sample(50000, step=[step1, step2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vec = trace.get_values('p_vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5b57c47898>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYDAUIEa4GwwGQwHy/wFXxg8V1z+0ggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5b71868438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(p_vec[:,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_mcmc_progs(mcmc_array, J, ind_samples=0):\n",
    "    \"\"\"\n",
    "    mcmc_array - output array from trace.get_values('variable_name')\n",
    "    J - number of classes\n",
    "    ind_samples - index to sum over, for example to sum over rows should be 0\n",
    "    \"\"\"\n",
    "    probs = np.zeros((mcmc_array.shape[int(not ind_samples)],3))\n",
    "    \n",
    "    for j in range(J):\n",
    "        \n",
    "        probs[:,j] = np.sum( np.isin(mcmc_array, [j]), ind_samples) / mcmc_array.shape[0]\n",
    "        \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_array = trace.get_values('t')\n",
    "ind_samples = 0\n",
    "count_mcmc_progs(mcmc_array, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
